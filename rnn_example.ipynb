{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.models.rnn import rnn_cell\n",
    "from tensorflow.models.rnn import rnn\n",
    "\n",
    "#Defining some hyper-params\n",
    "num_units = 2       #this is the parameter for input_size in the basic LSTM cell\n",
    "input_size = 2      #num_units and input_size will be the same\n",
    "\n",
    "batch_size = 50\n",
    "seq_len = 55\n",
    "num_epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will generate the data. This code was taken from the RNN example from the Lasagne.\n",
    "https://github.com/Lasagne/Lasagne/blob/master/examples/recurrent.py\n",
    "\n",
    "Summary of what type of data we are generating:\n",
    "\n",
    "    Generate a batch of sequences for the \"add\" task, e.g. the target for the\n",
    "    following\n",
    "    ``| 0.5 | 0.7 | 0.3 | 0.1 | 0.2 | ... | 0.5 | 0.9 | ... | 0.8 | 0.2 |\n",
    "      |  0  |  0  |  1  |  0  |  0  |     |  0  |  1  |     |  0  |  0  |``\n",
    "    would be 0.3 + .9 = 1.2. \n",
    "    \n",
    "The input and the output of the function gen_data:\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    min_length : int\n",
    "        Minimum sequence length.\n",
    "    max_length : int\n",
    "        Maximum sequence length.\n",
    "    n_batch : int\n",
    "        Number of samples in the batch.\n",
    "    Returns\n",
    "    -------\n",
    "    X : Input to the network, of shape (n_batch, max_length, 2), where the last\n",
    "        dimension corresponds to the two sequences shown above.\n",
    "    y : Correct output for each sample, shape (n_batch,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data(min_length=50, max_length=55, n_batch=5):\n",
    "\n",
    "    X = np.concatenate([np.random.uniform(size=(n_batch, max_length, 1)),\n",
    "                        np.zeros((n_batch, max_length, 1))],\n",
    "                       axis=-1)\n",
    "    y = np.zeros((n_batch,))\n",
    "    # Compute masks and correct values\n",
    "    for n in range(n_batch):\n",
    "        # Randomly choose the sequence length\n",
    "        length = np.random.randint(min_length, max_length)\n",
    "        #i changed this to a constant\n",
    "        #length=55\n",
    "\n",
    "        # Zero out X after the end of the sequence\n",
    "        X[n, length:, 0] = 0\n",
    "        # Set the second dimension to 1 at the indices to add\n",
    "        X[n, np.random.randint(length/2-1), 1] = 1\n",
    "        X[n, np.random.randint(length/2, length), 1] = 1\n",
    "        # Multiply and sum the dimensions of X to get the target value\n",
    "        y[n] = np.sum(X[n, :, 0]*X[n, :, 1])\n",
    "    # Center the inputs and outputs\n",
    "    #X -= X.reshape(-1, 2).mean(axis=0)\n",
    "    #y -= y.mean()\n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Model Construction\n",
    "\n",
    "cell = rnn_cell.BasicLSTMCell(num_units)    #we use the basic LSTM cell provided in TensorFlow\n",
    "                                            #num units is the input-size for this cell\n",
    "\n",
    "#create placeholders for X and y\n",
    "\n",
    "inputs = [tf.placeholder(tf.float32,shape=[batch_size,input_size]) for _ in range(seq_len)]\n",
    "result = tf.placeholder(tf.float32, shape=[batch_size])\n",
    "\n",
    "outputs, states = rnn.rnn(cell, inputs, dtype=tf.float32)   #note that outputs is a list of seq_len\n",
    "                                                            #each element is a tensor of size [batch_size,num_units]\n",
    "\n",
    "outputs2 = outputs[-1]   #we actually only need the last output from the model, ie: last element of outputs\n",
    "\n",
    "\n",
    "#We actually want the output to be size [batch_size, 1]\n",
    "#So we will implement a linear layer to do this\n",
    "\n",
    "W_o = tf.Variable(tf.random_normal([2,1], stddev=0.01))     \n",
    "b_o = tf.Variable(tf.random_normal([1], stddev=0.01))\n",
    "\n",
    "outputs2 = outputs[-1]\n",
    "\n",
    "outputs3 = tf.matmul(outputs2,W_o) + b_o       \n",
    "\n",
    "cost = tf.reduce_mean(tf.pow(outputs3-result,2))    #compute the cost for this batch of data\n",
    "\n",
    "#compute updates to parameters in order to minimize cost\n",
    "\n",
    "#train_op = tf.train.GradientDescentOptimizer(0.008).minimize(cost)\n",
    "train_op = tf.train.RMSPropOptimizer(0.005, 0.2).minimize(cost) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Generate Validation Data\n",
    "tempX,y_val = gen_data(50,seq_len,batch_size)\n",
    "X_val = []\n",
    "for i in range(seq_len):\n",
    "    X_val.append(tempX[:,i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Execute\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    tf.initialize_all_variables().run()     #initialize all variables in the model\n",
    "\n",
    "    for k in range(num_epochs):\n",
    "\n",
    "        #Generate Data for each epoch\n",
    "        #What this does is it creates a list of of elements of length seq_len, each of size [batch_size,input_size]\n",
    "        #this is required to feed data into rnn.rnn\n",
    "        tempX,y = gen_data(50,seq_len,batch_size)\n",
    "        X = []\n",
    "        for i in range(seq_len):\n",
    "            X.append(tempX[:,i,:])\n",
    "\n",
    "        #Create the dictionary of inputs to feed into sess.run\n",
    "        temp_dict = {inputs[i]:X[i] for i in range(seq_len)}\n",
    "        temp_dict.update({result: y})\n",
    "\n",
    "        sess.run(train_op,feed_dict=temp_dict)   #perform an update on the parameters\n",
    "\n",
    "        val_dict = {inputs[i]:X_val[i] for i in range(seq_len)}  #create validation dictionary\n",
    "        val_dict.update({result: y_val})\n",
    "        c_val = sess.run(cost, feed_dict = val_dict )            #compute the cost on the validation set\n",
    "        \n",
    "        print \"Validation cost: {}, on Epoch {}\".format(c_val,k)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
